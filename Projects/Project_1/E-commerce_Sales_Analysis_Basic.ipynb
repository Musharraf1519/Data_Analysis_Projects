{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f94b9764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "\n",
      "--- First 5 rows of the dataset ---\n",
      "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "0       1  CA-2016-152156  2016-11-08  2016-11-11    Second Class    CG-12520   \n",
      "1       2  CA-2016-152156  2016-11-08  2016-11-11    Second Class    CG-12520   \n",
      "2       3  CA-2016-138688  2016-06-12  2016-06-16    Second Class    DV-13045   \n",
      "3       4  US-2015-108966  2015-10-11  2015-10-18  Standard Class    SO-20335   \n",
      "4       5  US-2015-108966  2015-10-11  2015-10-18  Standard Class    SO-20335   \n",
      "\n",
      "     Customer Name    Segment        Country             City  ...  \\\n",
      "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
      "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
      "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
      "\n",
      "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
      "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
      "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
      "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
      "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
      "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
      "\n",
      "                                        Product Name     Sales  Quantity  \\\n",
      "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
      "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
      "\n",
      "   Discount    Profit  \n",
      "0      0.00   41.9136  \n",
      "1      0.00  219.5820  \n",
      "2      0.00    6.8714  \n",
      "3      0.45 -383.0310  \n",
      "4      0.20    2.5164  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "# Make sure 'Online Retail.xlsx' is in the same directory as your script/notebook,\n",
    "# or provide the full path to the file.\n",
    "try:\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\91987\\\\Desktop\\\\DATA_Analytics\\\\Projects\\\\Data_Analysis_Projects\\\\Projects\\\\Project_1\\\\samplesuperstore.csv\",encoding='ISO-8859-1')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Online Retail.xlsx' not found. Please ensure the file is in the correct directory.\")\n",
    "    # Exit or handle the error appropriately\n",
    "    exit() # You might remove this if you're in an interactive environment\n",
    "\n",
    "# --- Initial Inspection ---\n",
    "\n",
    "print(\"\\n--- First 5 rows of the dataset ---\")\n",
    "print(df.head())\n",
    "\n",
    "# print(\"\\n--- Dataset Information (Data Types, Non-Null Counts) ---\")\n",
    "# df.info()\n",
    "\n",
    "# print(\"\\n--- Descriptive Statistics for Numerical Columns ---\")\n",
    "# print(df.describe())\n",
    "\n",
    "# print(\"\\n--- Number of Duplicate Rows ---\")\n",
    "# print(f\"Total duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "# print(\"\\n--- Unique values in 'Customer ID' (first 10) ---\")\n",
    "# print(df['Customer ID'].unique()[:10]) # Show first 10 unique customer IDs\n",
    "\n",
    "# print(\"\\n--- Unique values in 'Country' ---\")\n",
    "# print(df['Country'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b4a3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaning Data ---\n",
      "(9994, 21)\n",
      "9994\n",
      "21\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['Description']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7972\\367363683.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# 1. Handle Missing Values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Drop rows where 'Description' is missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0minitial_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mRemoved rows with missing Description. Remaining rows: \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m (\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0minitial_rows\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m dropped)\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# # Drop rows where 'CustomerID' is missing (important for customer-level analysis)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\91987\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   6666\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6667\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6669\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6670\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6673\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mthresh\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['Description']"
     ]
    }
   ],
   "source": [
    "# --- Data Cleaning and Preprocessing ---\n",
    "\n",
    "print(\"\\n--- Cleaning Data ---\")\n",
    "\n",
    "# Drop rows where 'CustomerID' is missing (important for customer-level analysis)\n",
    "print(df.shape)      # Output: (3, 2)\n",
    "print(df.shape[0])   # Output: 3 (rows)\n",
    "print(df.shape[1])   # Output: 2 (columns)\n",
    "\n",
    "# 1. Handle Missing Values\n",
    "# Drop rows where 'Description' is missing\n",
    "initial_rows = df.shape[0]\n",
    "df.dropna(subset=['Description'], inplace=True)\n",
    "print(f\"Removed rows with missing Description. Remaining rows: {df.shape[0]} ({initial_rows - df.shape[0]} dropped)\")\n",
    "\n",
    "# # Drop rows where 'CustomerID' is missing (important for customer-level analysis)\n",
    "# initial_rows_after_desc = df.shape[0]\n",
    "# df.dropna(subset=['CustomerID'], inplace=True)\n",
    "# print(f\"Removed rows with missing CustomerID. Remaining rows: {df.shape[0]} ({initial_rows_after_desc - df.shape[0]} dropped)\")\n",
    "\n",
    "# # 2. Correct Data Types\n",
    "# # Convert 'InvoiceDate' to datetime objects\n",
    "# df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "# print(\"\\n'InvoiceDate' converted to datetime.\")\n",
    "\n",
    "# # Ensure 'Quantity' and 'UnitPrice' are numeric. Errors will turn into NaN, which we can then drop.\n",
    "# # This handles potential non-numeric entries if they exist (less common with Excel read_excel)\n",
    "# df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')\n",
    "# df['UnitPrice'] = pd.to_numeric(df['UnitPrice'], errors='coerce')\n",
    "# df.dropna(subset=['Quantity', 'UnitPrice'], inplace=True) # Drop rows where conversion failed\n",
    "# print(\"'Quantity' and 'UnitPrice' ensured to be numeric and NaNs removed.\")\n",
    "\n",
    "# # 3. Filter out Negative/Zero values and Cancelled Orders\n",
    "# # Remove transactions with negative or zero Quantity (returns, errors)\n",
    "# initial_rows_after_cust = df.shape[0]\n",
    "# df = df[df['Quantity'] > 0]\n",
    "# print(f\"Removed rows with Quantity <= 0. Remaining rows: {df.shape[0]} ({initial_rows_after_cust - df.shape[0]} dropped)\")\n",
    "\n",
    "# # Remove transactions with UnitPrice <= 0 (free items, errors)\n",
    "# initial_rows_after_qty = df.shape[0]\n",
    "# df = df[df['UnitPrice'] > 0]\n",
    "# print(f\"Removed rows with UnitPrice <= 0. Remaining rows: {df.shape[0]} ({initial_rows_after_qty - df.shape[0]} dropped)\")\n",
    "\n",
    "# # Remove cancelled orders (InvoiceNo starting with 'C')\n",
    "# initial_rows_after_price = df.shape[0]\n",
    "# df = df[~df['InvoiceNo'].astype(str).str.startswith('C')] # Convert to string before checking\n",
    "# print(f\"Removed cancelled orders. Remaining rows: {df.shape[0]} ({initial_rows_after_price - df.shape[0]} dropped)\")\n",
    "\n",
    "\n",
    "# # Remove duplicate rows after all other cleaning steps, as some might become duplicates\n",
    "# # after filtering (though less likely for this dataset).\n",
    "# initial_rows_final_check = df.shape[0]\n",
    "# df.drop_duplicates(inplace=True)\n",
    "# print(f\"Removed duplicate rows. Remaining rows: {df.shape[0]} ({initial_rows_final_check - df.shape[0]} dropped)\")\n",
    "\n",
    "\n",
    "# # Convert CustomerID to integer (they are float due to NaNs initially)\n",
    "# df['CustomerID'] = df['CustomerID'].astype(int)\n",
    "# print(\"\\n'CustomerID' converted to integer.\")\n",
    "\n",
    "\n",
    "# # --- Verification after Cleaning ---\n",
    "# print(\"\\n--- Dataset Information After Cleaning ---\")\n",
    "# df.info()\n",
    "\n",
    "# print(\"\\n--- Descriptive Statistics After Cleaning ---\")\n",
    "# print(df.describe())\n",
    "\n",
    "# print(\"\\n--- First 5 rows of the CLEANED dataset ---\")\n",
    "# print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
